{"instance_id": "astropy__astropy-11693", "model_name_or_path": "gpt-5", "model_patch": "*** Begin Patch\n*** Update File: astropy/wcs/wcsapi/fitswcs.py\n@@\n from itertools import chain\n \n import numpy as np\n \n from astropy import units as u\n+from astropy.wcs import NoConvergence\n from astropy.wcs.wcsapi.wrappers.sliced_wcs import _item_to_tuple\n from astropy.wcs.wcsapi.wrappers.sliced_wcs import sanitize_slices\n from astropy.wcs.wcsapi.low_level_api import validate_physical_types\n from astropy.wcs.wcsapi.low_level_api import (\n     BaseLowLevelWCS, BaseWCSWrapper, BaseLowLevelWCSWithAxes,\n@@\n         for x in world_arrays:\n             if not isinstance(x, u.Quantity):\n                 raise TypeError('world_to_pixel only accepts Quantities with units')\n \n     def world_to_pixel_values(self, *world_arrays):\n-        pixel = self.all_world2pix(*world_arrays, 0)\n+        try:\n+            pixel = self.all_world2pix(*world_arrays, 0)\n+        except NoConvergence:\n+            pixel = self.all_world2pix(*world_arrays, 0, quiet=True)\n         return pixel[0] if self.pixel_n_dim == 1 else tuple(pixel)\n \n     def array_index_to_world_values(self, *index_arrays):\n         # The input arrays should be for the 'input' order below\n         return self.pixel_to_world_values(*index_arrays)\n*** End Patch"}
{"instance_id": "astropy__astropy-12057", "model_name_or_path": "gpt-5", "model_patch": "*** Begin Patch\n*** Add File: astropy/nddata/uncertainty_converters.py\n+import numpy as np\n+\n+from .nduncertainty import StdDevUncertainty, VarianceUncertainty, InverseVariance\n+\n+\n+def _unit_pow(unit, power):\n+    if unit is None:\n+        return None\n+    return unit ** power\n+\n+\n+def _std_to_var(obj):\n+    return VarianceUncertainty(obj.array ** 2, unit=_unit_pow(obj.unit, 2))\n+\n+\n+def _var_to_invvar(obj):\n+    return InverseVariance(1.0 / obj.array, unit=_unit_pow(obj.unit, -1))\n+\n+\n+def _invvar_to_var(obj):\n+    return VarianceUncertainty(1.0 / obj.array, unit=_unit_pow(obj.unit, -1))\n+\n+\n+def _var_to_std(obj):\n+    return StdDevUncertainty(np.sqrt(obj.array), unit=_unit_pow(obj.unit, 0.5))\n+\n+\n+_FUNC_MAP = {\n+    (StdDevUncertainty, VarianceUncertainty): _std_to_var,\n+    (StdDevUncertainty, InverseVariance): lambda x: _var_to_invvar(_std_to_var(x)),\n+    (VarianceUncertainty, StdDevUncertainty): _var_to_std,\n+    (VarianceUncertainty, InverseVariance): _var_to_invvar,\n+    (InverseVariance, StdDevUncertainty): lambda x: _var_to_std(_invvar_to_var(x)),\n+    (InverseVariance, VarianceUncertainty): _invvar_to_var,\n+    (StdDevUncertainty, StdDevUncertainty): lambda x: x,\n+    (VarianceUncertainty, VarianceUncertainty): lambda x: x,\n+    (InverseVariance, InverseVariance): lambda x: x,\n+}\n+\n+\n+def convert_uncertainty(obj, new_class):\n+    if isinstance(obj, new_class):\n+        return obj\n+    func = _FUNC_MAP.get((type(obj), new_class))\n+    if func is None:\n+        raise TypeError(\n+            f\"Cannot convert uncertainty of type {type(obj).__name__} to {getattr(new_class, '__name__', new_class)}\"\n+        )\n+    return func(obj)\n+\n*** End Patch"}
{"instance_id": "astropy__astropy-12318", "model_name_or_path": "gpt-5", "model_patch": "*** Begin Patch\n*** Update File: astropy/modeling/blackbody.py\n@@\n from astropy import units as u\n from astropy.utils.exceptions import AstropyUserWarning\n \n@@\n     @property\n     def bolometric_flux(self):\n-        return (const.sigma_sb / np.pi * self.temperature ** 4 * self.scale).to(u.erg / (u.cm ** 2 * u.s))\n+        # Treat scale strictly as a dimensionless factor to avoid unintended unit scaling\n+        sc = self.scale\n+        if isinstance(sc, u.Quantity):\n+            sc = sc.to_value(u.dimensionless_unscaled)\n+        return (const.sigma_sb / np.pi * self.temperature ** 4 * sc).to(u.erg / (u.cm ** 2 * u.s))\n*** End Patch"}
{"instance_id": "astropy__astropy-12544", "model_name_or_path": "gpt-5", "model_patch": "*** Begin Patch\n*** Update File: astropy/table/table.py\n@@\n \n     @classmethod\n     def read(cls, *args, **kwargs):\n-        return io_registry.read(cls, *args, **kwargs)\n+        # Optional API to disable masked columns in returned table\n+        mask_opt = kwargs.pop('mask', None)\n+        out = io_registry.read(cls, *args, **kwargs)\n+        if mask_opt is False:\n+            try:\n+                import numpy as np\n+                from .column import MaskedColumn\n+            except Exception:\n+                return out\n+            if isinstance(out, Table):\n+                new = cls()\n+                # Preserve table-level meta and attributes\n+                try:\n+                    new.meta = out.meta.copy() if hasattr(out.meta, \"copy\") else out.meta\n+                except Exception:\n+                    new.meta = out.meta\n+                for name in out.colnames:\n+                    col = out[name]\n+                    if isinstance(col, MaskedColumn):\n+                        kind = col.dtype.kind\n+                        # Determine appropriate fill strategy\n+                        if kind in 'f':\n+                            data = col.filled(np.nan)\n+                        elif kind in 'c':\n+                            data = col.filled(np.nan + 0j)\n+                        elif kind in 'iu':\n+                            data = col.astype(float).filled(np.nan)\n+                        elif kind in 'SU':\n+                            data = col.astype(object).filled(None)\n+                        elif kind in 'O':\n+                            data = col.filled(None)\n+                        else:\n+                            # Fallback: use existing fill_value or None\n+                            fv = getattr(col, 'fill_value', None)\n+                            data = col.filled(fv)\n+                        new[name] = data\n+                        # Preserve per-column metadata\n+                        try:\n+                            new[name].unit = getattr(col, 'unit', None)\n+                        except Exception:\n+                            pass\n+                        try:\n+                            new[name].description = getattr(col, 'description', None)\n+                        except Exception:\n+                            pass\n+                        fmt = getattr(col, 'format', None)\n+                        if fmt is not None:\n+                            try:\n+                                new[name].format = fmt\n+                            except Exception:\n+                                pass\n+                        cmeta = getattr(col, 'meta', None)\n+                        if cmeta:\n+                            try:\n+                                new[name].meta = cmeta.copy() if hasattr(cmeta, \"copy\") else cmeta\n+                            except Exception:\n+                                new[name].meta = cmeta\n+                    else:\n+                        # Ensure we don't propagate a MaskedColumn\n+                        new.add_column(col.copy(), name=name)\n+                return new\n+        return out\n \n     def write(self, *args, **kwargs):\n         io_registry.write(self, *args, **kwargs)\n*** End Patch"}
{"instance_id": "astropy__astropy-12825", "model_name_or_path": "gpt-5", "model_patch": "*** Begin Patch\n*** Update File: astropy/coordinates/sky_coordinate.py\n@@\n class SkyCoord(BaseRepresentationOrDifferential, ShapedLikeCoordinate, BaseCoordinateFrame):\n     \"\"\"\n     High-level class for representing a celestial coordinate.\n     \"\"\"\n \n+    @property\n+    def groups(self):\n+        return self.info.groups\n+\n+    @groups.setter\n+    def groups(self, value):\n+        self.info.groups = value\n+\n+    @groups.deleter\n+    def groups(self):\n+        del self.info.groups\n+\n     def __getattr__(self, attr):\n         \"\"\"\n         Shorthand for accessing the `~astropy.coordinates.SkyCoord` attributes\n         and methods on the \"frame\" objects, i.e., e.g.\n         ``icrs.ra`` is shortcut for ``icrs.frame.ra``.\n*** End Patch"}
{"instance_id": "astropy__astropy-12842", "model_name_or_path": "gpt-5", "model_patch": "*** Begin Patch\n*** Update File: astropy/io/ascii/ecsv.py\n@@\n ECSV_DATATYPES = (\n     'bool', 'int8', 'int16', 'int32', 'int64',\n     'uint8', 'uint16', 'uint32', 'uint64',\n-    'float16', 'float32', 'float64', 'float128', 'string'\n+    'float16', 'float32', 'float64', 'float128', 'string',\n+    'datetime64'\n )\n*** End Patch"}
{"instance_id": "astropy__astropy-12880", "model_name_or_path": "gpt-5", "model_patch": "*** Begin Patch\n*** Update File: astropy/io/ascii/ecsv.py\n@@     def get_cols(self, lines):\n-            if col.dtype not in ECSV_DATATYPES:\n-                raise ValueError(f'datatype {col.dtype!r} of column {col.name!r} '\n-                                 f'is not in allowed values {ECSV_DATATYPES}')\n+            if col.dtype not in ECSV_DATATYPES:\n+                # Allow legacy ECSV 0.9 files that used 'datetime64' as a datatype.\n+                # This preserves backward compatibility with files written by older\n+                # versions of astropy (e.g., 4.2.1) and avoids raising on read.\n+                if col.dtype != 'datetime64':\n+                    raise ValueError(f'datatype {col.dtype!r} of column {col.name!r} '\n+                                     f'is not in allowed values {ECSV_DATATYPES}')\n*** End Patch"}
{"instance_id": "astropy__astropy-12891", "model_name_or_path": "gpt-5", "model_patch": "*** Begin Patch\n*** Update File: astropy/units/quantity.py\n@@\n         return result\r\n \r\n     def mean(self, axis=None, dtype=None, out=None, keepdims=False):\r\n         \"\"\"\r\n         Take the mean over the given axis.\r\n \r\n         Parameters\r\n         ----------\r\n         axis : int or tuple of ints, optional\r\n             Axis or axes along which the means are computed. The default is\r\n             to compute the mean of the flattened array.\r\n         dtype : ~numpy.dtype\r\n             Type to use in computing the means.  For integer inputs, the\r\n             default is float64; for inexact inputs, it is the same as the\r\n             input dtype.\r\n         out : `~numpy.ndarray`, optional\r\n             Alternate output array in which to place the result.  Must have\r\n             the same shape and buffer length as the expected output, but the\r\n             type will be cast if necessary.\r\n         keepdims : bool, optional\r\n             If this is set to True, the axes which are reduced are left in\r\n             the result as dimensions with size one.  With this option, the\r\n             result will broadcast correctly against the input array.\r\n \r\n         Returns\r\n         -------\r\n         mean : `~astropy.units.Quantity`\r\n             The result of the mean.\r\n         \"\"\"\r\n-        out_array = self.view(np.ndarray).mean(axis=axis, dtype=dtype,\r\n-                                               out=_get_ndarray_out(out),\r\n-                                               keepdims=keepdims)\r\n-        if out is None:\r\n-            return out_array * self.unit\r\n-        else:\r\n-            out_array = out_array.view(type(self))\r\n-            out_array._set_unit(self.unit)\r\n-            return out_array\r\n+        return self.mean(axis=axis, dtype=dtype, out=out, keepdims=keepdims, where=True)\r\n+\r\n+    def mean(self, axis=None, dtype=None, out=None, keepdims=False, *, where=True):\r\n+        \"\"\"\r\n+        Take the mean over the given axis.\r\n+\r\n+        Added support for numpy's 'where' keyword.\r\n+        \"\"\"\r\n+        # Convert `where` if it is a Quantity (must be dimensionless)\r\n+        try:\r\n+            _ = where.unit  # detect Quantity-like\r\n+        except AttributeError:\r\n+            pass\r\n+        else:\r\n+            from . import dimensionless_unscaled as _one\r\n+            where = where.to_value(_one).astype(bool, copy=False)\r\n+\r\n+        out_nd = _get_ndarray_out(out)\r\n+        out_array = self.view(np.ndarray).mean(axis=axis, dtype=dtype,\r\n+                                               out=out_nd,\r\n+                                               keepdims=keepdims,\r\n+                                               where=where)\r\n+        if out is None:\r\n+            return out_array * self.unit\r\n+        else:\r\n+            out_array = out_array.view(type(self))\r\n+            out_array._set_unit(self.unit)\r\n+            return out_array\r\n*** End Patch"}
{"instance_id": "astropy__astropy-12907", "model_name_or_path": "gpt-5", "model_patch": "*** Begin Patch\n*** Update File: astropy/modeling/separable.py\n@@\n def separability_matrix(model):\n-    if getattr(model, 'separable', None) is True:\n-        return np.ones((model.n_outputs, model.n_inputs), dtype=bool)\n+    # For separable models with equal numbers of inputs/outputs, each output depends\n+    # on exactly one input, so the separability matrix is the identity.\n+    # This ensures nested CompoundModels formed via '&' preserve separability.\n+    if getattr(model, 'separable', None) is True:\n+        if model.n_outputs == model.n_inputs:\n+            return np.eye(model.n_outputs, dtype=bool)\n+        return np.ones((model.n_outputs, model.n_inputs), dtype=bool)\n*** End Patch"}
{"instance_id": "astropy__astropy-12962", "model_name_or_path": "gpt-5", "model_patch": "*** Begin Patch\n*** Update File: astropy/nddata/ccddata.py\n@@\n         return ccd\n \n-    def to_hdu(self, hdu_mask='MASK', hdu_uncertainty='UNCERT', wcs_relax=False,\n-               key_uncertainty='BUNIT'):\n+    def to_hdu(self, hdu_mask='MASK', hdu_uncertainty='UNCERT', wcs_relax=False,\n+               key_uncertainty='BUNIT', as_image_hdu=False):\n         \"\"\"\n         Convert to an `~astropy.io.fits.HDUList` object.\n \n         Parameters\n         ----------\n         hdu_mask : str, optional\n             The name of the extension that will store the mask.\n         hdu_uncertainty : str, optional\n             The name of the extension that will store the uncertainty.\n         wcs_relax : bool or int, optional\n             Degree of permissiveness for writing invalid WCS. See\n             `astropy.wcs.WCS.to_header` for more information.\n         key_uncertainty : str, optional\n             The header key name for the unit of the uncertainty.  This\n             keyword is only used if the uncertainty has an *unit*\n             attribute.\n+        as_image_hdu : bool, optional\n+            If True, the first HDU containing the image data will be an\n+            ImageHDU instead of a PrimaryHDU. This is useful for appending\n+            the image as an extension to an existing FITS file.\n \n         Returns\n         -------\n         `~astropy.io.fits.HDUList`\n             A list of HDUs.\n \n         Notes\n         -----\n         Mask and uncertainty are saved as extensions to the image HDU to\n         ensure that ``ccd = CCDData.read(ccd.to_hdu())`` is similar to the\n         original CCDData object.\n \n         WCS is always written to the FITS header of the first HDU. If the\n         WCS information cannot be written to the header as FITS keywords\n         it will be discarded.\n         \"\"\"\n         from astropy.io import fits\n \n-        hdu = fits.PrimaryHDU(self.data)\n+        hdu_class = fits.ImageHDU if as_image_hdu else fits.PrimaryHDU\n+        hdu = hdu_class(self.data)\n \n         # Update header with WCS info, if present\n         if self.wcs is not None:\n             try:\n                 hdr = self.wcs.to_header(relax=wcs_relax)\n             except Exception:\n                 hdr = None\n             if hdr is not None:\n                 # Only update with items to avoid clobbering the entire header\n                 for key, val in hdr.items():\n                     # fits.Header joins comments with the value using a tuple\n                     # assign to preserve comments if present\n                     if isinstance(val, tuple) and len(val) == 2:\n                         hdu.header[key] = (val[0], val[1])\n                     else:\n                         hdu.header[key] = val\n \n         # Update header with any meta information. This cannot use the meta\n         # attribute setter in the normal way because that tries to get the\n         # header from the data attribute...which this just created.\n         if isinstance(self.meta, fits.Header):\n             for card in self.meta.cards:\n                 if card.keyword == 'HISTORY':\n                     hdu.header.add_history(card.value)\n                 elif card.keyword == 'COMMENT':\n                     hdu.header.add_comment(card.value)\n                 else:\n                     hdu.header[card.keyword] = card.value\n         else:\n             try:\n                 hdu.header.update(self.meta)\n             except TypeError:\n                 raise TypeError('meta must be a dict or Header object.')\n \n         # Update header with units\n         if self.unit is not None:\n             hdu.header['BUNIT'] = self.unit.to_string()\n \n         hdus = [hdu]\n \n         # Save mask, if present, as an image hdu.\n         if self.mask is not None:\n             mask_hdu = fits.ImageHDU(self.mask.astype(np.uint8), name=hdu_mask)\n             hdus.append(mask_hdu)\n \n         # Save uncertainty, if present, as an image hdu.\n         if self.uncertainty is not None:\n             # uncertainty should always have an array attribute\n             if hasattr(self.uncertainty, 'array'):\n                 unc = self.uncertainty.array\n             else:\n                 unc = self.uncertainty\n             uncert_hdu = fits.ImageHDU(unc, name=hdu_uncertainty)\n             # Save the unit of the uncertainty, if it exists\n             if hasattr(self.uncertainty, 'unit') and self.uncertainty.unit is not None:\n                 uncert_hdu.header[key_uncertainty] = self.uncertainty.unit.to_string()\n             hdus.append(uncert_hdu)\n \n         return fits.HDUList(hdus)\n*** End Patch"}
{"instance_id": "astropy__astropy-13032", "model_name_or_path": "gpt-5", "model_patch": "*** Begin Patch\n*** Update File: astropy/modeling/bounding_box.py\n@@\n     @property\n     def ignored_inputs(self):\n-        return self._ignored_inputs\n+        return tuple(self._ignored_inputs)\n \n*** End Patch"}
{"instance_id": "astropy__astropy-13033", "model_name_or_path": "gpt-5", "model_patch": "*** Begin Patch\n*** Update File: astropy/timeseries/timeseries.py\n@@\n class TimeSeries(QTable):\n     \"\"\"\n     A class to represent time series data.\n     \"\"\"\n \n+    def _required_columns_set(self):\n+        \"\"\"\n+        Return the set of required column names as an immutable set.\n+        \"\"\"\n+        required = getattr(self, '_required_columns', ['time'])\n+        # Ensure deterministic immutable return as per project guidelines\n+        return frozenset(required)\n+\n+    def _check_required_columns_not_removed(self, names, action='remove'):\n+        # Normalize names to a set\n+        if isinstance(names, (str, bytes)):\n+            names_set = {names}\n+        else:\n+            names_set = set(names)\n+\n+        required = set(self._required_columns_set())\n+        to_be_removed = required.intersection(names_set)\n+        if to_be_removed:\n+            # Construct a clear and actionable error message\n+            if len(to_be_removed) == 1:\n+                col = next(iter(to_be_removed))\n+                raise ValueError(f\"Cannot {action} required column '{col}' from TimeSeries\")\n+            else:\n+                cols = \", \".join(sorted(to_be_removed))\n+                raise ValueError(f\"Cannot {action} required columns [{cols}] from TimeSeries\")\n+\n+    def remove_column(self, name):\n+        self._check_required_columns_not_removed(name, action='remove')\n+        return super().remove_column(name)\n+\n+    def remove_columns(self, names):\n+        self._check_required_columns_not_removed(names, action='remove')\n+        return super().remove_columns(names)\n+\n+    def keep_columns(self, names):\n+        # Ensure all required columns are kept\n+        required = set(self._required_columns_set())\n+        names_set = set(names)\n+        missing = required.difference(names_set)\n+        if missing:\n+            if len(missing) == 1:\n+                col = next(iter(missing))\n+                raise ValueError(f\"Cannot drop required column '{col}' from TimeSeries; it must be included in keep_columns\")\n+            else:\n+                cols = \", \".join(sorted(missing))\n+                raise ValueError(f\"Cannot drop required columns [{cols}] from TimeSeries; they must be included in keep_columns\")\n+        return super().keep_columns(names)\n+\n+    def __delitem__(self, item):\n+        # Deleting a column via del ts['col']\n+        self._check_required_columns_not_removed(item, action='remove')\n+        return super().__delitem__(item)\n+\n*** End Patch"}
{"instance_id": "astropy__astropy-13068", "model_name_or_path": "gpt-5", "model_patch": "*** Begin Patch\n*** Update File: astropy/time/formats.py\n@@\n class TimeJD(TimeFloat):\n     \"\"\"\n     Julian Date time format.\n     \"\"\"\n     name = 'jd'\n     unit = 1.0\n     _interval_factor = 1.0\n     epoch_scale = None\n \n     def set_jds(self, val1, val2):\n-        super().set_jds(val1, val2)\n+        # Split JD such that the first part is near a half day. This improves\n+        # precision when converting to calendar dates by keeping the day\n+        # fraction small in magnitude, avoiding precision loss for large JD.\n+        if val2 is None:\n+            jd = np.asanyarray(val1, dtype=np.float64)\n+        else:\n+            jd = np.asanyarray(val1, dtype=np.float64) + np.asanyarray(val2, dtype=np.float64)\n+        jd1 = np.floor(jd) + 0.5\n+        jd2 = jd - jd1\n+        self.jd1 = jd1\n+        self.jd2 = jd2\n \n     @property\n     def value(self):\n         return self.jd1 + self.jd2\n \n*** End Patch"}
{"instance_id": "astropy__astropy-13073", "model_name_or_path": "gpt-5", "model_patch": "*** Begin Patch\n*** Update File: docs/io/ascii/read.rst\n@@\n Converters\n ----------\n \n+Reading boolean columns from True/False\n+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n+\n+By default, columns that contain the string values \"True\" and \"False\" are read as strings. To interpret these as boolean values, supply explicit converters that try int, float, bool, and finally str, for every column:\n+\n+.. code-block:: python\n+\n+    from astropy.table import Table\n+    from astropy.io.ascii import convert_numpy\n+\n+    converters = {'*': [convert_numpy(typ) for typ in (int, float, bool, str)]}\n+    t = Table.read(\"filename.txt\", format=\"ascii\", converters=converters)\n+\n+This preserves existing behavior for non-boolean string columns while allowing True/False columns to be read as booleans.\n+\n*** End Patch"}
{"instance_id": "astropy__astropy-13075", "model_name_or_path": "gpt-5", "model_patch": "*** Begin Patch\n*** Add File: astropy/cosmology/io/html.py\n+from __future__ import annotations\n+\n+from astropy.io.registry import register_writer\n+from astropy.table import QTable\n+\n+from ..core import Cosmology\n+from .table import to_table\n+\n+\n+def write_html(cosmology: Cosmology, file, *, tablecls=QTable, **kwargs):\n+    \"\"\"Write Cosmology to an HTML table.\"\"\"\n+    table = to_table(cosmology, tablecls=tablecls)\n+    table.write(file, format=\"html\", **kwargs)\n+\n+\n+register_writer(\"html\", Cosmology, write_html)\n+\n*** End Patch"}
{"instance_id": "astropy__astropy-13132", "model_name_or_path": "gpt-5", "model_patch": "*** Begin Patch\n*** Update File: astropy/time/core.py\n@@\n         return result\n \n     # Ensure descriptor order for comparisons.\n     __lt__ = _Ordering.lt\n     __le__ = _Ordering.le\n+\n+    # numpy array function protocol\n+    def __array_function__(self, func, types, args, kwargs):\n+        # Only implement what we explicitly support\n+        import numpy as np\n+\n+        if func is np.linspace:\n+            # Extract arguments following numpy.linspace signature\n+            # linspace(start, stop, num=50, endpoint=True, retstep=False, dtype=None, axis=0)\n+            if len(args) >= 2:\n+                start, stop = args[0], args[1]\n+            else:\n+                start = kwargs.get('start', None)\n+                stop = kwargs.get('stop', None)\n+\n+            if not (isinstance(start, Time) and isinstance(stop, Time)):\n+                return NotImplemented\n+\n+            num = kwargs.get('num', 50)\n+            endpoint = kwargs.get('endpoint', True)\n+            retstep = kwargs.get('retstep', False)\n+            dtype = kwargs.get('dtype', None)\n+            axis = kwargs.get('axis', 0)\n+\n+            # Only support default axis to avoid complex dimension insertion logic\n+            if axis != 0:\n+                return NotImplemented\n+            # Dtype is not meaningful for Time; require default\n+            if dtype is not None:\n+                raise TypeError(\"dtype argument is not supported for Time.linspace\")\n+\n+            # Compute linear interpolation using TimeDelta\n+            delta = stop - start\n+            frac = np.linspace(0.0, 1.0, num=num, endpoint=endpoint, dtype=float)\n+            # Reshape fractions to broadcast across any existing dimensions of delta\n+            if delta.shape:\n+                frac = frac.reshape((num,) + (1,) * delta.ndim)\n+            # increments is TimeDelta array with leading dimension num\n+            increments = delta * frac\n+            result = start + increments\n+\n+            if retstep:\n+                denom = (num - 1) if endpoint else num\n+                if denom > 0:\n+                    step = delta / denom\n+                else:\n+                    # Match numpy behavior where step becomes NaN when denom == 0\n+                    step = delta * np.nan\n+                return (result, step)\n+            else:\n+                return result\n+\n+        return NotImplemented\n*** End Patch"}
{"instance_id": "astropy__astropy-13158", "model_name_or_path": "gpt-5", "model_patch": "*** Begin Patch\n*** Update File: astropy/modeling/core.py\n@@\n                 else:\r\n                     value = getattr(self, name).value\r\n                     # set the unit to be correct for this parameter set\r\n                     if raw:\r\n                         unit = None\r\n-                    else:\r\n+                    else:\r\n                         unit = getattr(self, name).unit\r\n                 # Quantities must be unitless and thus will be destroyed\r\n                 # with ``value = np.array(...)``.  Otherwise, this is a list\r\n                 # of parameter values.\r\n                 # But don't make a copy of \"value\" which may be large and\r\n                 # have been created anew when unitless with getattr()\r\n-                if unit is not None:\r\n-                    value = Quantity(value, unit)\r\n+                if unit is not None:\r\n+                    try:\r\n+                        value = Quantity(value, unit)\r\n+                    except u.UnitTypeError:\r\n+                        # For function/logarithmic units (e.g., magnitudes), Quantity(value, unit)\r\n+                        # is not allowed. In that case, preserve any existing quantity,\r\n+                        # or create the appropriate quantity via unit multiplication.\r\n+                        if not isinstance(value, u.Quantity):\r\n+                            value = unit * value\r\n                 values.append(value)\r\n \r\n         if len(set(shapes)) != 1 or units:\r\n             # If the parameters are not all the same shape, converting to an\r\n             # array is going to produce an object array\r\n*** End Patch"}
{"instance_id": "astropy__astropy-13162", "model_name_or_path": "gpt-5", "model_patch": "*** Begin Patch\n*** Update File: astropy/coordinates/angles.py\n@@\n \n def dms_to_degrees(d, m, s):\n-    sign = np.sign(d)\n-    d, m, s = np.abs(d), np.abs(m), np.abs(s)\n-    return sign * (d + m / 60.0 + s / 3600.0)\n+    d_arr = np.asanyarray(d, dtype=float)\n+    m_arr = np.asanyarray(m, dtype=float)\n+    s_arr = np.asanyarray(s, dtype=float)\n+    # Determine the sign from the first non-zero component among (d, m, s)\n+    sign_d = np.sign(d_arr)\n+    sign_m = np.sign(m_arr)\n+    sign_s = np.sign(s_arr)\n+    sign = np.where(d_arr != 0, sign_d, np.where(m_arr != 0, sign_m, sign_s))\n+    # If all components are zero, default to positive sign\n+    sign = np.where(sign == 0, 1.0, sign)\n+    return sign * (np.abs(d_arr) + np.abs(m_arr) / 60.0 + np.abs(s_arr) / 3600.0)\n*** End Patch"}
{"instance_id": "astropy__astropy-13234", "model_name_or_path": "gpt-5", "model_patch": "*** Begin Patch\n*** Update File: astropy/table/serialize.py\n@@\n def _construct_mixin_from_columns(name, obj_attrs, out):\n     \"\"\"\n     Construct a single mixin column from the serialized YAML object in\n     ``obj_attrs`` and add it to the table ``out``.\n     \"\"\"\n-    data_attrs_map = {}\n+    data_attrs_map = {}\n     if 'name' in obj_attrs:\n         # Case of only a single attribute that is a reference to a column\n         data_attrs_map[obj_attrs['name']] = 'data'\n     elif 'data' in obj_attrs:\n         # Case of multiple attributes referring to columns, e.g. for\n         # structured arrays.  E.g.:\n         # obj_attrs['data'] = {'x': {'name': 'col.x'}, 'y': {'name': 'col.y'}}\n-        for name, val in obj_attrs['data'].items():\n-            data_attrs_map[val['name']] = name\n+        for name, val in obj_attrs['data'].items():\n+            # Unwrap nested SerializedColumn objects to get the plain column name.\n+            # In cases where a structured field itself is named 'name', the YAML\n+            # round-trip can produce nested SerializedColumn objects, so ensure we\n+            # drill down until we get a string reference like 'col.field'.\n+            ref = val\n+            try:\n+                # Loop while ref is a mapping-like with a 'name' entry that itself\n+                # is not a string. This robustly handles any nesting depth.\n+                while isinstance(ref, dict) and 'name' in ref and not isinstance(ref['name'], str):\n+                    ref = ref['name']\n+                if isinstance(ref, dict) and 'name' in ref:\n+                    ref = ref['name']\n+            except Exception:\n+                # Fallback: if anything goes wrong, just use val['name'] as-is\n+                # (previous behavior). This keeps compatibility for unexpected types.\n+                ref = val['name']\n+            data_attrs_map[ref] = name\n     else:\n         raise ValueError('no \"name\" or \"data\" in obj_attrs={}'.format(obj_attrs))\n \n     # Now get the reference columns and build up the object initialization attributes.\n     # Also remove the reference columns from the table.\n*** End Patch"}
{"instance_id": "astropy__astropy-13236", "model_name_or_path": "gpt-5", "model_patch": "*** Begin Patch\n*** Update File: astropy/table/table.py\n@@\n import copy\n import itertools\n import os\n import sys\n import textwrap\n+import warnings\n \n import numpy as np\n \n from astropy.utils.compat import NUMPY_LT_2_0\n from astropy.utils.metadata import Metadata\n@@\n \n         # Structured ndarray gets viewed as a mixin unless already a valid\n         # mixin class\n         if (not isinstance(data, Column) and not data_is_mixin\n                 and isinstance(data, np.ndarray) and len(data.dtype) > 1):\n+            warnings.warn(\n+                \"Adding a structured numpy array to a Table will be added as a Column in a future release (5.2). \"\n+                \"To ensure it remains a Column now and in the future, wrap the data in Column(...).\",\n+                FutureWarning,\n+                stacklevel=3,\n+            )\n             data = data.view(NdarrayMixin)\n             data_is_mixin = True\n*** End Patch"}
